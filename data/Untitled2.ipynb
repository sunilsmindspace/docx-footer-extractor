{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262223d5-e5de-4c72-b66f-2d440c68817f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 .docx files to process:\n",
      "  - CS Log file handling.docx\n",
      "  - CS ExamCardsDatabaseService_Voxel_D002055389_RevA.docx\n",
      "  - CS ExamCards verA.docx\n",
      "  - CS Connectivity_R13.0_D002055364_RevA.docx\n",
      "  - CS Exam Overview_verA.docx\n",
      "  - CS PDT Voxel.docx\n",
      "  - ComponentSpecifications_MR-RT_RTgo5.13_D002050479_RevA.docx\n",
      "  - CS DicomConfigTool_R13.0_D002055371_RevA.docx\n",
      "  - CS LayoutManagerService__verA.docx\n",
      "Processed: CS Log file handling.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: CS ExamCardsDatabaseService_Voxel_D002055389_RevA.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: CS ExamCards verA.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: CS Connectivity_R13.0_D002055364_RevA.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: CS Exam Overview_verA.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: CS PDT Voxel.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: ComponentSpecifications_MR-RT_RTgo5.13_D002050479_RevA.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: CS DicomConfigTool_R13.0_D002055371_RevA.docx\n",
      "  Found 5 metadata entries\n",
      "Processed: CS LayoutManagerService__verA.docx\n",
      "  Found 5 metadata entries\n",
      "\n",
      "Processed 9 files from folder.\n",
      "CS Log file handling.docx of type docx: 2001001526\n",
      "CS ExamCardsDatabaseService_Voxel_D002055389_RevA.docx of type docx: 2001001526\n",
      "CS ExamCards verA.docx of type docx: 2001001526\n",
      "CS Connectivity_R13.0_D002055364_RevA.docx of type docx: 2001001526\n",
      "CS Exam Overview_verA.docx of type docx: 2001001526\n",
      "CS PDT Voxel.docx of type docx: 2001001526\n",
      "ComponentSpecifications_MR-RT_RTgo5.13_D002050479_RevA.docx of type docx: 2001001526\n",
      "CS DicomConfigTool_R13.0_D002055371_RevA.docx of type docx: 2001001526\n",
      "CS LayoutManagerService__verA.docx of type docx: 2001001526\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Dict, Union\n",
    "import threading\n",
    "\n",
    "class DocxMetadataExtractor:\n",
    "    def __init__(self, max_workers: int = None):\n",
    "        \"\"\"\n",
    "        Initialize the DOCX metadata extractor.\n",
    "        \n",
    "        Args:\n",
    "            max_workers: Maximum number of worker threads. If None, uses default ThreadPoolExecutor behavior.\n",
    "        \"\"\"\n",
    "        self.max_workers = max_workers\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def extract_key_values(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Extract key-value pairs from text where pairs are separated by colons.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text containing key-value pairs\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of key-value pairs\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for line in text.split('\\n'):\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                result[key.strip()] = value.strip()\n",
    "        return result\n",
    "    \n",
    "    def get_kv(self, data: List[tuple]) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Extract key-value pairs from a list of tuples.\n",
    "        \n",
    "        Args:\n",
    "            data: List of tuples containing text data\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing all extracted key-value pairs\n",
    "        \"\"\"\n",
    "        doc_info = {}\n",
    "        \n",
    "        for entry in data:\n",
    "            for part in entry:\n",
    "                if part and part.strip():  # skip empty strings\n",
    "                    doc_info.update(self.extract_key_values(part))\n",
    "        \n",
    "        return doc_info\n",
    "    \n",
    "    def process_single_file(self, filepath: str) -> Dict[str, Union[str, Dict[str, str]]]:\n",
    "        \"\"\"\n",
    "        Process a single DOCX file and extract metadata from footers.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Full path to the DOCX file to process\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing filename and metadata\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filepath)\n",
    "        \n",
    "        try:\n",
    "            doc = Document(filepath)\n",
    "            all_metadata = {}\n",
    "            \n",
    "            # Get all sections in the document\n",
    "            for section in doc.sections:\n",
    "                footer = section.footer\n",
    "                \n",
    "                # Extract text from footer paragraphs\n",
    "                footer_text = []\n",
    "                for paragraph in footer.paragraphs:\n",
    "                    if paragraph.text.strip():  # Only add non-empty paragraphs\n",
    "                        footer_text.append(paragraph.text.strip())\n",
    "                \n",
    "                # Process footer text for key-value pairs\n",
    "                for text in footer_text:\n",
    "                    all_metadata.update(self.extract_key_values(text))\n",
    "                \n",
    "                # Extract text from footer tables\n",
    "                for table in footer.tables:\n",
    "                    table_data = [tuple(c.text for c in r.cells) for r in table.rows]\n",
    "                    table_metadata = self.get_kv(table_data)\n",
    "                    all_metadata.update(table_metadata)\n",
    "            \n",
    "            return {\n",
    "                \"filename\": filename,\n",
    "                \"metadata\": all_metadata\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return filename with error information\n",
    "            return {\n",
    "                \"filename\": filename,\n",
    "                \"metadata\": {\"error\": str(e)}\n",
    "            }\n",
    "    \n",
    "    def _get_file_list(self, input_source: Union[str, List[str]]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get list of DOCX files from input source.\n",
    "        \n",
    "        Args:\n",
    "            input_source: Either a folder path or list of file paths\n",
    "            \n",
    "        Returns:\n",
    "            List of full file paths\n",
    "        \"\"\"\n",
    "        if isinstance(input_source, str):\n",
    "            # Input is a folder path\n",
    "            if not os.path.exists(input_source):\n",
    "                raise FileNotFoundError(f\"Folder not found: {input_source}\")\n",
    "            \n",
    "            if not os.path.isdir(input_source):\n",
    "                raise NotADirectoryError(f\"Path is not a directory: {input_source}\")\n",
    "            \n",
    "            # Get all .docx files in the folder\n",
    "            docx_files = []\n",
    "            for filename in os.listdir(input_source):\n",
    "                if filename.endswith('.docx'):\n",
    "                    docx_files.append(os.path.join(input_source, filename))\n",
    "            \n",
    "            if not docx_files:\n",
    "                raise ValueError(f\"No .docx files found in folder: {input_source}\")\n",
    "            \n",
    "            return docx_files\n",
    "        \n",
    "        elif isinstance(input_source, list):\n",
    "            # Input is a list of file paths\n",
    "            if not input_source:\n",
    "                raise ValueError(\"File list is empty\")\n",
    "            \n",
    "            # Validate files exist and are .docx files\n",
    "            valid_files = []\n",
    "            for filepath in input_source:\n",
    "                if not os.path.exists(filepath):\n",
    "                    print(f\"Warning: File not found: {filepath}\")\n",
    "                    continue\n",
    "                \n",
    "                if not filepath.endswith('.docx'):\n",
    "                    print(f\"Warning: Not a .docx file: {filepath}\")\n",
    "                    continue\n",
    "                \n",
    "                valid_files.append(filepath)\n",
    "            \n",
    "            if not valid_files:\n",
    "                raise ValueError(\"No valid .docx files found in the provided list\")\n",
    "            \n",
    "            return valid_files\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"Input must be either a folder path (string) or list of file paths\")\n",
    "    \n",
    "    def extract_metadata(self, input_source: Union[str, List[str]]) -> List[Dict[str, Union[str, Dict[str, str]]]]:\n",
    "        \"\"\"\n",
    "        Extract metadata from DOCX files using parallel processing.\n",
    "        \n",
    "        Args:\n",
    "            input_source: Either a folder path (string) or list of file paths (list)\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries, each containing 'filename' and 'metadata' keys\n",
    "        \"\"\"\n",
    "        # Get list of files to process\n",
    "        file_list = self._get_file_list(input_source)\n",
    "        \n",
    "        print(f\"Found {len(file_list)} .docx files to process:\")\n",
    "        for filepath in file_list:\n",
    "            print(f\"  - {os.path.basename(filepath)}\")\n",
    "        \n",
    "        # Process files in parallel\n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_file = {\n",
    "                executor.submit(self.process_single_file, filepath): filepath \n",
    "                for filepath in file_list\n",
    "            }\n",
    "            \n",
    "            # Collect results as they complete\n",
    "            for future in future_to_file:\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    # Thread-safe printing\n",
    "                    with self.lock:\n",
    "                        print(f\"Processed: {result['filename']}\")\n",
    "                        if result['metadata'] and 'error' not in result['metadata']:\n",
    "                            print(f\"  Found {len(result['metadata'])} metadata entries\")\n",
    "                        elif 'error' in result['metadata']:\n",
    "                            print(f\"  Error: {result['metadata']['error']}\")\n",
    "                        else:\n",
    "                            print(f\"  No metadata found\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    filepath = future_to_file[future]\n",
    "                    filename = os.path.basename(filepath)\n",
    "                    with self.lock:\n",
    "                        print(f\"Error processing {filename}: {e}\")\n",
    "                    results.append({\n",
    "                        \"filename\": filename,\n",
    "                        \"metadata\": {\"error\": str(e)}\n",
    "                    })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_results_to_file(self, results: List[Dict[str, Union[str, Dict[str, str]]]], output_file: str = \"metadata_results.txt\"):\n",
    "        \"\"\"\n",
    "        Save the extraction results to a text file.\n",
    "        \n",
    "        Args:\n",
    "            results: List of dictionaries from extract_metadata\n",
    "            output_file: Name of the output file\n",
    "        \"\"\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"DOCX Metadata Extraction Results\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            for result in results:\n",
    "                f.write(f\"File: {result['filename']}\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                \n",
    "                metadata = result['metadata']\n",
    "                if metadata:\n",
    "                    for key, value in metadata.items():\n",
    "                        f.write(f\"{key}: {value}\\n\")\n",
    "                else:\n",
    "                    f.write(\"No metadata found\\n\")\n",
    "                \n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create extractor\n",
    "    extractor = DocxMetadataExtractor(max_workers=4)\n",
    "    \n",
    "    # Example 1: Process all DOCX files in a folder\n",
    "    try:\n",
    "        results = extractor.extract_metadata(\".\")\n",
    "        print(f\"\\nProcessed {len(results)} files from folder.\")\n",
    "        \n",
    "        # Access results\n",
    "        for result in results:\n",
    "            file_name = result['filename']\n",
    "            file_type = os.path.splitext(file_name)[1].lstrip('.')\n",
    "            template_id = result['metadata'].get('Template Number', 'N/A')\n",
    "            print(f\"{file_name} of type {file_type}: {template_id}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder: {e}\")\n",
    "    \n",
    "    # # Example 2: Process specific list of files\n",
    "    # file_list = [\n",
    "    #     \"document1.docx\",\n",
    "    #     \"document2.docx\",\n",
    "    #     \"path/to/document3.docx\"\n",
    "    # ]\n",
    "    \n",
    "    # try:\n",
    "    #     results = extractor.extract_metadata(file_list)\n",
    "    #     print(f\"\\nProcessed {len(results)} files from list.\")\n",
    "        \n",
    "    #     # Optionally save results to file\n",
    "    #     extractor.save_results_to_file(results)\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error processing file list: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d4785-3d41-4a08-9eb8-e38a37b40f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
