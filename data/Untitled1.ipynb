{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826e0266-87b9-4ddc-8cdb-2b3f49ba9634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 .docx files:\n",
      "  - CS Log file handling.docx\n",
      "  - CS ExamCardsDatabaseService_Voxel_D002055389_RevA.docx\n",
      "  - CS ExamCards verA.docx\n",
      "  - CS Connectivity_R13.0_D002055364_RevA.docx\n",
      "  - CS Exam Overview_verA.docx\n",
      "  - CS PDT Voxel.docx\n",
      "  - ComponentSpecifications_MR-RT_RTgo5.13_D002050479_RevA.docx\n",
      "  - CS DicomConfigTool_R13.0_D002055371_RevA.docx\n",
      "  - CS LayoutManagerService__verA.docx\n",
      "Processed: ./CS Log file handling.docx\n",
      "  Metadata: {'Document ID': 'D002054507', 'Document Revision': '', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./CS ExamCardsDatabaseService_Voxel_D002055389_RevA.docx\n",
      "  Metadata: {'Document ID': 'D002055389', 'Document Revision': 'A', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./CS ExamCards verA.docx\n",
      "  Metadata: {'Document ID': 'D002064158', 'Document Revision': 'A', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./CS Connectivity_R13.0_D002055364_RevA.docx\n",
      "  Metadata: {'Document ID': 'D002055364', 'Document Revision': 'A', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./CS Exam Overview_verA.docx\n",
      "  Metadata: {'Document ID': 'D002064334', 'Document Revision': 'A', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./CS PDT Voxel.docx\n",
      "  Metadata: {'Document ID': '', 'Document Revision': '', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./ComponentSpecifications_MR-RT_RTgo5.13_D002050479_RevA.docx\n",
      "  Metadata: {'Document ID': 'Doc_ID', 'Document Revision': 'Rev_Level', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./CS DicomConfigTool_R13.0_D002055371_RevA.docx\n",
      "  Metadata: {'Document ID': 'D002055371', 'Document Revision': 'A', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "Processed: ./CS LayoutManagerService__verA.docx\n",
      "  Metadata: {'Document ID': 'D002066655', 'Document Revision': 'A', 'Template Number': '2001001526', 'Template Version': '2', 'Philips Information Classification': 'Internal'}\n",
      "\n",
      "Processing complete! Processed 9 files.\n",
      "Results saved to: metadata_results.txt\n",
      "\n",
      "./CS Log file handling.docx: 5 metadata entries\n",
      "\n",
      "./CS ExamCardsDatabaseService_Voxel_D002055389_RevA.docx: 5 metadata entries\n",
      "\n",
      "./CS ExamCards verA.docx: 5 metadata entries\n",
      "\n",
      "./CS Connectivity_R13.0_D002055364_RevA.docx: 5 metadata entries\n",
      "\n",
      "./CS Exam Overview_verA.docx: 5 metadata entries\n",
      "\n",
      "./CS PDT Voxel.docx: 5 metadata entries\n",
      "\n",
      "./ComponentSpecifications_MR-RT_RTgo5.13_D002050479_RevA.docx: 5 metadata entries\n",
      "\n",
      "./CS DicomConfigTool_R13.0_D002055371_RevA.docx: 5 metadata entries\n",
      "\n",
      "./CS LayoutManagerService__verA.docx: 5 metadata entries\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import threading\n",
    "\n",
    "class DocxMetadataExtractor:\n",
    "    def __init__(self, max_workers: int = None):\n",
    "        \"\"\"\n",
    "        Initialize the DOCX metadata extractor.\n",
    "        \n",
    "        Args:\n",
    "            max_workers: Maximum number of worker threads. If None, uses default ThreadPoolExecutor behavior.\n",
    "        \"\"\"\n",
    "        self.max_workers = max_workers\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def extract_key_values(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Extract key-value pairs from text where pairs are separated by colons.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text containing key-value pairs\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of key-value pairs\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for line in text.split('\\n'):\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                result[key.strip()] = value.strip()\n",
    "        return result\n",
    "    \n",
    "    def get_kv(self, data: List[Tuple]) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Extract key-value pairs from a list of tuples.\n",
    "        \n",
    "        Args:\n",
    "            data: List of tuples containing text data\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing all extracted key-value pairs\n",
    "        \"\"\"\n",
    "        doc_info = {}\n",
    "        \n",
    "        for entry in data:\n",
    "            for part in entry:\n",
    "                if part and part.strip():  # skip empty strings\n",
    "                    doc_info.update(self.extract_key_values(part))\n",
    "        \n",
    "        return doc_info\n",
    "    \n",
    "    def process_single_file(self, filename: str) -> Tuple[str, Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Process a single DOCX file and extract metadata from footers.\n",
    "        \n",
    "        Args:\n",
    "            filename: Name of the DOCX file to process\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing (filename, extracted_metadata_dict)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            doc = Document(filename)\n",
    "            all_metadata = {}\n",
    "            \n",
    "            # Get all sections in the document\n",
    "            for section in doc.sections:\n",
    "                footer = section.footer\n",
    "                \n",
    "                # Extract text from footer paragraphs\n",
    "                footer_text = []\n",
    "                for paragraph in footer.paragraphs:\n",
    "                    if paragraph.text.strip():  # Only add non-empty paragraphs\n",
    "                        footer_text.append(paragraph.text.strip())\n",
    "                \n",
    "                # Process footer text for key-value pairs\n",
    "                for text in footer_text:\n",
    "                    all_metadata.update(self.extract_key_values(text))\n",
    "                \n",
    "                # Extract text from footer tables\n",
    "                for table in footer.tables:\n",
    "                    table_data = [tuple(c.text for c in r.cells) for r in table.rows]\n",
    "                    table_metadata = self.get_kv(table_data)\n",
    "                    all_metadata.update(table_metadata)\n",
    "            \n",
    "            return (filename, all_metadata)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return filename with error information\n",
    "            return (filename, {\"error\": str(e)})\n",
    "    \n",
    "    def get_metadata_footer_parallel(self, folder: str = '.') -> List[Tuple[str, Dict[str, str]]]:\n",
    "        \"\"\"\n",
    "        Extract metadata from all DOCX files in a folder using parallel processing.\n",
    "        \n",
    "        Args:\n",
    "            folder: Path to the folder containing DOCX files (default: current directory)\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples containing (filename, metadata_dict) for each file\n",
    "        \"\"\"\n",
    "        # Get all .docx files in the specified folder\n",
    "        docs = [f for f in os.listdir(folder) if f.endswith('.docx')]\n",
    "        \n",
    "        if not docs:\n",
    "            print(f\"No .docx files found in folder: {folder}\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"Found {len(docs)} .docx files:\")\n",
    "        for file in docs:\n",
    "            print(f\"  - {file}\")\n",
    "        \n",
    "        # Process files in parallel\n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_file = {\n",
    "                executor.submit(self.process_single_file, os.path.join(folder, doc)): doc \n",
    "                for doc in docs\n",
    "            }\n",
    "            \n",
    "            # Collect results as they complete\n",
    "            for future in future_to_file:\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    # Thread-safe printing\n",
    "                    with self.lock:\n",
    "                        print(f\"Processed: {result[0]}\")\n",
    "                        if result[1]:  # If metadata was found\n",
    "                            print(f\"  Metadata: {result[1]}\")\n",
    "                        else:\n",
    "                            print(f\"  No metadata found\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    filename = future_to_file[future]\n",
    "                    with self.lock:\n",
    "                        print(f\"Error processing {filename}: {e}\")\n",
    "                    results.append((filename, {\"error\": str(e)}))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_results_to_file(self, results: List[Tuple[str, Dict[str, str]]], output_file: str = \"metadata_results.txt\"):\n",
    "        \"\"\"\n",
    "        Save the extraction results to a text file.\n",
    "        \n",
    "        Args:\n",
    "            results: List of tuples from get_metadata_footer_parallel\n",
    "            output_file: Name of the output file\n",
    "        \"\"\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"DOCX Metadata Extraction Results\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            for filename, metadata in results:\n",
    "                f.write(f\"File: {filename}\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                \n",
    "                if metadata:\n",
    "                    for key, value in metadata.items():\n",
    "                        f.write(f\"{key}: {value}\\n\")\n",
    "                else:\n",
    "                    f.write(\"No metadata found\\n\")\n",
    "                \n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create extractor with default number of workers\n",
    "    extractor = DocxMetadataExtractor()\n",
    "    \n",
    "    # Extract metadata from all DOCX files in current directory\n",
    "    results = extractor.get_metadata_footer_parallel()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nProcessing complete! Processed {len(results)} files.\")\n",
    "    \n",
    "    # Optionally save results to file\n",
    "    extractor.save_results_to_file(results)\n",
    "    \n",
    "    # Access individual results\n",
    "    for filename, metadata in results:\n",
    "        print(f\"\\n{filename}: {len(metadata)} metadata entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812410d-4ac0-45b6-8dfa-aa33f0f8bf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
